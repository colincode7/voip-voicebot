{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce9dcf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependencies for Pyvoip\n",
    "import pyVoIP\n",
    "from pyVoIP.VoIP import CallState, VoIPPhone, InvalidStateError\n",
    "import time\n",
    "import wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90addb13-d1be-496e-b7fa-26776977c96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables imported from kubernetes or network-specific\n",
    "#pod name for file instance and grabbing credentials\n",
    "pod = \"pod1\"\n",
    "#sip extension\n",
    "extension = \"1001\"\n",
    "#sip extension password\n",
    "extension_password = \"password\"\n",
    "#myIP\n",
    "IP = \"x.x.x.x\"\n",
    "#Asterisk server ip\n",
    "asteriskip = \"x.x.x.x\"\n",
    "#Asterisk server trunk\n",
    "trunkname = \"\"\n",
    "#caller id\n",
    "caller_id = \"\"\n",
    "#context on asterisk\n",
    "context = \"\"\n",
    "#ftp target directory for callfile\n",
    "ftp_directory\n",
    "\n",
    "#mongo notes\n",
    "uri = \"\"\n",
    "db_name = \"\"\n",
    "collection_name = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45755eb-2bed-43de-bf8b-c5489523478b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function whose purpose is to grab phone numbers from a MongoDB\n",
    "#function for grabbing phone number, another ChatGPT creation\n",
    "import pymongo\n",
    "import random\n",
    "\n",
    "def remove_random_phone_number(uri, db_name, collection_name):\n",
    "    \"\"\"\n",
    "    Remove a random phone number from MongoDB and return the removed phone number.\n",
    "\n",
    "    Parameters:\n",
    "    - uri (str): The connection URI for MongoDB.\n",
    "    - db_name (str): The name of the MongoDB database.\n",
    "    - collection_name (str): The name of the collection in the database.\n",
    "\n",
    "    Returns:\n",
    "    - str or None: The removed phone number, or None if no phone number was removed.\n",
    "    \"\"\"\n",
    "    # Connect to MongoDB\n",
    "    myclient = pymongo.MongoClient(uri)\n",
    "\n",
    "    # Access the specified database and collection\n",
    "    mydb = myclient[db_name]\n",
    "    mycol = mydb[collection_name]\n",
    "\n",
    "    # Count the number of documents in the collection\n",
    "    count = mycol.count_documents({})\n",
    "\n",
    "    if count == 0:\n",
    "        print(\"No phone numbers found in the database.\")\n",
    "        return None\n",
    "\n",
    "    # Generate a random index\n",
    "    random_index = random.randint(0, count - 1)\n",
    "\n",
    "    # Find a random document from the collection\n",
    "    random_document = mycol.find().skip(random_index).limit(1)[0]\n",
    "\n",
    "    # Remove the random document from the collection\n",
    "    result = mycol.delete_one({\"_id\": random_document[\"_id\"]})\n",
    "\n",
    "    if result.deleted_count == 1:\n",
    "        print(f\"Random phone number '{random_document['phone_number']}' removed successfully.\")\n",
    "        return random_document['phone_number']\n",
    "    else:\n",
    "        print(\"Failed to remove random phone number.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1f7d29-8b12-4d97-90c6-1a714ad3b9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ftplib import FTP\n",
    "#call_making function, relies on the Asterisk callfile format\n",
    "#grabs phone number from Asterisk db, then makes a call\n",
    "def generate_call_file(filename, channel, context, extension, priority, caller_id, max_retry=0, retry_time=60):\n",
    "    \"\"\"\n",
    "    Generate a call file for Asterisk PBX server.\n",
    "\n",
    "    Parameters:\n",
    "    - filename (str): The filename for the call file to be generated.\n",
    "    - channel (str): The channel to use for the call (e.g., SIP/1001). Format SIP/trunkname/phone-number\n",
    "    - context (str): The context in the dialplan to send the call to.\n",
    "    - extension (str): The extension to dial.\n",
    "    - priority (int): The priority in the dialplan to execute.\n",
    "    - caller_id (str): The caller ID to display.\n",
    "    - max_retry (int): Maximum number of retries in case of failure (default: 3).\n",
    "    - retry_time (int): Time to wait between retries in seconds (default: 60).\n",
    "    \"\"\"\n",
    "    #note this doesn't include the WaitTime parameter, which defaults to 45 seconds of waiting to see if call will answer. \n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(f\"Channel: {channel}\\n\")\n",
    "        f.write(f\"Context: {context}\\n\")\n",
    "        f.write(f\"Extension: {extension}\\n\")\n",
    "        f.write(f\"Priority: {priority}\\n\")\n",
    "        f.write(f\"Callerid: \\\"{caller_id}\\\"\\n\")\n",
    "        f.write(f\"MaxRetries: {max_retry}\\n\")\n",
    "        f.write(f\"RetryTime: {retry_time}\\n\")\n",
    "\n",
    "def upload_call_file_via_ftp(filename, ftp_host, ftp_user, ftp_pass, ftp_outgoing_dir):\n",
    "    \"\"\"\n",
    "    Upload a call file to the Asterisk server's outgoing directory using FTP.\n",
    "\n",
    "    Parameters:\n",
    "    - filename (str): The filename of the call file to be uploaded.\n",
    "    - ftp_host (str): The hostname or IP address of the FTP server.\n",
    "    - ftp_user (str): The FTP username.\n",
    "    - ftp_pass (str): The FTP password.\n",
    "    - ftp_outgoing_dir (str): The path to the Asterisk server's outgoing directory.\n",
    "    \"\"\"\n",
    "    with FTP(ftp_host) as ftp:\n",
    "        ftp.login()\n",
    "        ftp.cwd(ftp_outgoing_dir)\n",
    "        with open(filename, 'rb') as file:\n",
    "            ftp.storbinary(f'STOR {filename}', file)\n",
    "\n",
    "def check_call_file_presence(filename, outgoing_dir):\n",
    "    \"\"\"\n",
    "    Check if the call file is present in the outgoing directory after a set amount of time.\n",
    "\n",
    "    Parameters:\n",
    "    - filename (str): The filename of the call file to check.\n",
    "    - outgoing_dir (str): The path to the Asterisk server's outgoing directory.\n",
    "    - timeout (int): The maximum time to wait for the file to appear (default: 30 seconds).\n",
    "    \"\"\"\n",
    "    ftp.login()\n",
    "    file_list = ftp.nlst(outgoing_dir)\n",
    "    for i in file_list:\n",
    "        if i == pod+\"call.call\":\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205399da-d935-437e-9ac8-00b41d09a3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#global variable for phone_number\n",
    "current_phone = ''\n",
    "#runs once when phone call starts, then either during final stage of successful phone call, or after hangup\n",
    "#no_passthrough indicates loop. Use call_made = False and no_passthrough = False for predictive dial, call_made = True and no_passthrough = True for post-dial\n",
    "def call_maker(no_passthrough,call_made):\n",
    "    timer = 0\n",
    "    warning_timer = 0\n",
    "    if no_passthrough == False:\n",
    "            current_phone = remove_random_phone_number(uri, db_name, collection_name)\n",
    "            generate_call_file(pod+\"call.call\",\"SIP/\"+trunkname+\"/\"+phone_number,context,extension,priority=1,caller_id)\n",
    "            upload_call_file_via_ftp(pod+\"call.call\",asteriskip,ftp_directory)\n",
    "    while call.state != CallState.ANSWERED and no_passthrough:\n",
    "        if call_made = False:\n",
    "            #function for grabbing phone number and writing it to remote file\n",
    "            current_phone = remove_random_phone_number(uri, db_name, collection_name)\n",
    "            generate_call_file(pod+\"call.call\",\"SIP/\"+trunkname+\"/\"+phone_number,context,extension,priority=1,caller_id)\n",
    "            upload_call_file_via_ftp(pod+\"call.call\",asteriskip,ftp_directory)\n",
    "            call_made = True\n",
    "        elif call_made = True and timer > 10:\n",
    "            #checks to make sure file is present\n",
    "            if check_file_presence(filename,outgoing_dir) == False:\n",
    "                call_made = False\n",
    "            else:\n",
    "                warning_timer += 10\n",
    "                timer = 0\n",
    "        elif warning_timer > 100:\n",
    "            call_made = False\n",
    "        elif warning_timer > 200:\n",
    "            raise TypeError(\"Asterisk Server Fault\")\n",
    "        else:\n",
    "            time.sleep(0.1)\n",
    "            timer += 0.1\n",
    "    return\n",
    "        #function for making call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed39c532-3eb0-4d78-abc0-afbbbcec9959",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recording of call transcripts in my MongoDB\n",
    "from datetime import datetime\n",
    "import pymongo\n",
    "uri = \"\"\n",
    "myclient = pymongo.MongoClient(uri)\n",
    "mydb = myclient[\"calltranscripts\"]\n",
    "#change cluster on column for future A/B testing\n",
    "mycol = mydb[\"Cluster A\"]\n",
    "\n",
    "#separate do not call db\n",
    "mydb1 = myclient[\"donotcall\"]\n",
    "mycol1 = mydb1[\"number_list\"]\n",
    "\n",
    "#this python function also thanks to ChatGPT\n",
    "def push_transcript(transcript):\n",
    "    if answering_machine < 2:\n",
    "        is_machine = True\n",
    "    else:\n",
    "        is_machine = False\n",
    "    transcript[\"is_machine\"] = is_machine\n",
    "    transcript[\"call_stage\"] = call_stage\n",
    "    transcript[\"datetime_start\"] = datetime_start\n",
    "    transcript[\"datetime_end\"] = datetime.now()\n",
    "    transcript[\"phone_number\"] = phone_number\n",
    "    x = mycol.insert_one(transcript)\n",
    "    return\n",
    "\n",
    "def do_not_call(phone_number):\n",
    "    x = mycol1.insert_one(phone_number)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ed0994d-2209-4f5f-a727-7ef563c644c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.83M/1.83M [00:00<00:00, 2.69MB/s]\n",
      "Downloading: \"https://github.com/snakers4/silero-vad/zipball/master\" to C:\\Users\\hmlay/.cache\\torch\\hub\\master.zip\n"
     ]
    }
   ],
   "source": [
    "#Dependencies for vad \n",
    "import wave\n",
    "import torch\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "from IPython.display import Audio\n",
    "from pprint import pprint\n",
    "\n",
    "USE_ONNX = False # change this to True if you want to test onnx model\n",
    "if USE_ONNX:\n",
    "    !pip install -q onnxruntime\n",
    "  \n",
    "model, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad',\n",
    "                              model='silero_vad',\n",
    "                              force_reload=True,\n",
    "                              onnx=USE_ONNX)\n",
    "\n",
    "(get_speech_timestamps,\n",
    " save_audio,\n",
    " read_audio,\n",
    " VADIterator,\n",
    " collect_chunks) = utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2657a696-3451-49d0-b675-382644de012a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependencies for faster-whisper\n",
    "from faster_whisper import WhisperModel\n",
    "\n",
    "model_size = \"base.en\"\n",
    "\n",
    "full_model_size = \"small.en\"\n",
    "\n",
    "#try compute_type float16 when implemented on arm\n",
    "\n",
    "model = WhisperModel(model_size, device=\"cpu\",compute_type=\"int8\")\n",
    "\n",
    "full_model = WhisperModel(full_model_size, device=\"cpu\",compute_type=\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d629c3b8-0351-4ed4-9c07-99916753516c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#global variable for current transcript\n",
    "current_transcript = ''\n",
    "full_transcript = ''\n",
    "\n",
    "def whisper_audio_transcript(audiofile):\n",
    "    segments, info = model.transcribe(audiofile, beam_size=5)\n",
    "    segments = list(segments)  # The transcription will actually run here.\n",
    "    transcript = ''\n",
    "    for segment in segments:\n",
    "        transcript += segment.text\n",
    "    return(transcript)\n",
    "\n",
    "#version for whisper_large\n",
    "\n",
    "def full_whisper(audiofile):\n",
    "    segments, info = full_model.transcribe(audiofile, beam_size=5)\n",
    "    segments = list(segments)  # The transcription will actually run here.\n",
    "    transcript = ''\n",
    "    for segment in segments:\n",
    "        transcript += segment.text\n",
    "    return(transcript)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03be2a7d-7e8a-41ac-84c4-fd01f35a6796",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 16:42:01 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
      "Using cache found in C:\\Users\\hmlay/.cache\\torch\\hub\\snakers4_silero-models_master\n"
     ]
    }
   ],
   "source": [
    "#Dependencies for RVC_Python and Silero TTS\n",
    "from rvc_python.infer import infer_file, infer_files\n",
    "\n",
    "#modify the below to change voice selection with Silero\n",
    "language = 'en'\n",
    "model_id = 'v3_en'\n",
    "sample_rate = 48000\n",
    "speaker = 'en_1'\n",
    "\n",
    "\n",
    "import torch\n",
    "device = torch.device('cpu')\n",
    "model, example_text = torch.hub.load(repo_or_dir='snakers4/silero-models',\n",
    "                                     model='silero_tts',\n",
    "                                     language=language,\n",
    "                                     speaker=model_id)\n",
    "model.to(device)\n",
    "\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0ac734f-e9f8-4b45-b6fa-0a25a07e8d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VAD: takes in audio file and the current audio transcript, and determines whether our speaker should start talking. \n",
    "\n",
    "#global variable \"talk_over_gap\" is actively adjusted to ensure that the AI doesn't repeatedly talk over you\n",
    "talk_over_gap = 0.2\n",
    "def vad(audiofile,audio_text):\n",
    "    wav = read_audio(audiofile, sampling_rate=8000)\n",
    "    # get speech timestamps from full audio file\n",
    "    speech_timestamps = get_speech_timestamps(wav, model, sampling_rate=8000)\n",
    "    last_speech = speech_timestamps[-1]\n",
    "    with wave.open(audiofile,'rb') as wf:\n",
    "        frames = wf.getnframes()\n",
    "    vocal_gap = (frames - last_speech['end'])/8000\n",
    "    #vocal_gap is measured in seconds. current target is the 200ms switching. incorporate variable in place of 0.2, etc in elif in order to get\n",
    "    #dynamic response time. Currently reliant on Whisper's punctuation. \n",
    "    if vocal_gap > 0.1:\n",
    "        tmp_audio_record = b''\n",
    "        vadnum += 1\n",
    "    if vocal_gap > talk_over_gap and audio_text[-1] in (\".\", \"!\", \"?\", \" \"):\n",
    "        return True\n",
    "    elif vocal_gap > talk_over_gap + 0.3:\n",
    "        return True\n",
    "    else:\n",
    "        return False    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f51af8e0-d843-47aa-994b-808d0014496a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tts(text2,destination_audiofile):\n",
    "    #Silero TTS. Using SSML. \n",
    "    audio = model.save_wav(ssml_text=text2, speaker=speaker, sample_rate=sample_rate, audio_path=r\"intermediate2.wav\")\n",
    "    sound = AudioSegment.from_wav(r\"intermediate2.wav\")\n",
    "\n",
    "    # Convert to 8-bit, 8000Hz mono\n",
    "    sound = sound.set_frame_rate(8000).set_channels(1).set_sample_width(1)\n",
    "\n",
    "    # Export the converted audio\n",
    "    sound.export(destination_audiofile, format=\"wav\")\n",
    "\n",
    "\n",
    "#full TTS function is available on tts_work ipynb, will likely deploy with Azure API for testing. Do try inference performance on Ampere Altra though. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dadf27a-9b25-4ff1-9f96-76ed6eedbc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#another ChatGPT-generated function. This one adds SSML tags, slowing speech down and adding breaks between sentences, and returns an array of sentences.\n",
    "def separate_into_sentences_with_ssml(input_string):\n",
    "    \"\"\"\n",
    "    Separate a string into an array of strings breaking at each sentence with SSML tagging.\n",
    "\n",
    "    Parameters:\n",
    "    - input_string (str): The input string.\n",
    "\n",
    "    Returns:\n",
    "    - list: An array of strings with SSML tagging.\n",
    "    \"\"\"\n",
    "    # Split the input string into sentences\n",
    "    sentences = input_string.split('. ')  # Assuming sentences end with period followed by space\n",
    "\n",
    "    # Initialize the list to store SSML tagged sentences\n",
    "    ssml_sentences = []\n",
    "\n",
    "    # Iterate through each sentence and add SSML tagging\n",
    "    for sentence in sentences:\n",
    "        # Add SSML elements for strong pause and set prosody rate to slow\n",
    "        ssml_sentence = f'<prosody rate=\"slow\">{sentence.strip()}</prosody><break strength=\"strong\"/>'\n",
    "        ssml_sentences.append(ssml_sentence)\n",
    "\n",
    "    return ssml_sentences\n",
    "\n",
    "#and another ChatGPT python function that removes any pesky trailing sentences\n",
    "\n",
    "def strip_sentences_without_punctuation(input_string):\n",
    "    \"\"\"\n",
    "    Strip off sentences in a string that don't end with appropriate punctuation.\n",
    "\n",
    "    Parameters:\n",
    "    - input_string (str): The input string.\n",
    "\n",
    "    Returns:\n",
    "    - str: The modified string with only sentences ending with appropriate punctuation.\n",
    "    \"\"\"\n",
    "    # Split the input string into sentences\n",
    "    sentences = input_string.split('. ')  # Assuming sentences end with period followed by space\n",
    "\n",
    "    # Initialize the list to store sentences with appropriate punctuation\n",
    "    valid_sentences = []\n",
    "\n",
    "    # Iterate through each sentence and check if it ends with appropriate punctuation\n",
    "    for sentence in sentences:\n",
    "        # Check if the sentence ends with \".\", \"!\", or \"?\"\n",
    "        if sentence.endswith(\".\") or sentence.endswith(\"!\") or sentence.endswith(\"?\"):\n",
    "            valid_sentences.append(sentence)\n",
    "\n",
    "    # Join the valid sentences to form the modified string\n",
    "    modified_string = '. '.join(valid_sentences)\n",
    "\n",
    "    return modified_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f923bcf-f367-42bf-aa8f-e710e328c83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#global variable for ongoing summary\n",
    "#global variable for call stage\n",
    "\n",
    "call_stage = 0\n",
    "\n",
    "#dependencies, using openai API architecture\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "#API connection, in this case to deepinfra\n",
    "openai = OpenAI(\n",
    "    api_key=\"<YOUR DEEPINFRA TOKEN: deepctl auth token>\",\n",
    "    base_url=\"https://api.deepinfra.com/v1/openai\",\n",
    ")\n",
    "\n",
    "#prompt that indicates what the system does, with list of one dictionary object indicating the start prompt\n",
    "system_prompt = []\n",
    "\n",
    "#prompt that indicates request is for filler sentence\n",
    "filler_response = [{\"role\":\"system\",\"content\":\"Craft a short filler sentence to respond while you think.\"}]\n",
    "\n",
    "#stage_responses\n",
    "\n",
    "#introduction\n",
    "stage_zero = [{\"role\":\"system\",\"content\":\"\"}]\n",
    "\n",
    "#sales\n",
    "stage_one = [{\"role\":\"system\",\"content\":\"\"}]\n",
    "\n",
    "#getting info\n",
    "stage_two = [{\"role\":\"system\",\"content\":\"\"]\n",
    "\n",
    "#thank you\n",
    "stage_three = [{\"role\":\"system\",\"content\":\"\"]\n",
    "\n",
    "def script(transcript,response,call_stage):\n",
    "    #hello!\n",
    "    if call_stage == 0:\n",
    "        chat_completion = openai.chat.completions.create(\n",
    "        model=\"cognitivecomputations/dolphin-2.6-mixtral-8x7b\",\n",
    "        messages= system_prompt+transcript+stage_zero,\n",
    "        stream=False, temperature = 1, presence_penalty = 1, frequency_penalty=-0.5,)\n",
    "    #casual conversation\n",
    "    elif: call_stage == 1:\n",
    "        chat_completion = openai.chat.completions.create(\n",
    "        model=\"cognitivecomputations/dolphin-2.6-mixtral-8x7b\",\n",
    "        messages= system_prompt+transcript+stage_one,\n",
    "        stream=False, temperature = 1, presence_penalty = 1, frequency_penalty=-0.5,)\n",
    "    #grabbing info\n",
    "    elif: call_stage == 2:\n",
    "        chat_completion = openai.chat.completions.create(\n",
    "        model=\"cognitivecomputations/dolphin-2.6-mixtral-8x7b\",\n",
    "        messages= system_prompt+transcript+stage_two,\n",
    "        stream=False, temperature = 1, presence_penalty = 1, frequency_penalty=-0.5,)\n",
    "    #if info grabbed, polite close\n",
    "    elif: call_stage == 3:\n",
    "        chat_completion = openai.chat.completions.create(\n",
    "        model=\"cognitivecomputations/dolphin-2.6-mixtral-8x7b\",\n",
    "        messages= system_prompt+transcript+stage_three,\n",
    "        stream=False, temperature = 1, presence_penalty = 1, frequency_penalty=-0.5,)\n",
    "\n",
    "    \n",
    "    return chat_completion\n",
    "\n",
    "def response(call):\n",
    "    chat_completion = openai.chat.completions.create(\n",
    "    model=\"cognitivecomputations/dolphin-2.6-mixtral-8x7b\",\n",
    "    messages= system_prompt+transcript+filler_response,\n",
    "    stream=False, temperature = 1, presence_penalty = 1, frequency_penalty=-0.5,max_tokens=40)\n",
    "    finished_response = strip_sentences_without_punctuation(chat_completion)\n",
    "    return finished_response\n",
    "\n",
    "#global variable for each call transcript\n",
    "transcript = []\n",
    "\n",
    "def update_transcript(transcript, caller_id, text):\n",
    "    \"\"\"\n",
    "    Update the transcript with the provided caller ID and text.\n",
    "\n",
    "    Parameters:\n",
    "    - transcript (dict): The transcript dictionary.\n",
    "    - caller_id (str): The caller ID.\n",
    "    - text (str): The text message.\n",
    "\n",
    "    Returns:\n",
    "    - dict: The updated transcript.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a dictionary element for the current update\n",
    "    update_element = {\"role\": caller_id, \"content\": text}\n",
    "    \n",
    "    # Add the update element to the transcript\n",
    "    transcript.append(update_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e27fbcc-8906-494b-ad45-1f03f177450c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for writing audio file to call\n",
    "def call_writer(audiofile):\n",
    "    f = wave.open(audiofile, 'rb')\n",
    "    frames = f.getnframes()\n",
    "    data = f.readframes(frames)\n",
    "    f.close()\n",
    "    call.answer()\n",
    "    call.write_audio(data)  # This writes the audio data to the transmit buffer, this must be bytes.\n",
    "    #add function that sleeps for length of audio to prevent overwriting or building buffer\n",
    "    time.sleep(frames/8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7665a6-bbce-45a1-a345-a47e9365c7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for profanity and explicit detection\n",
    "#another simple chatgpt creation\n",
    "\n",
    "def profanity_checker(transcript):\n",
    "    \"\"\"\n",
    "    Identify if a certain number of banned words occur in a transcript.\n",
    "\n",
    "    Parameters:\n",
    "    - transcript (list): The transcript list.\n",
    "    - banned_words (list): The list of banned words.\n",
    "    - threshold (int): The threshold count for banned words.\n",
    "\n",
    "    Returns:\n",
    "    - bool: True if the count of banned words exceeds the threshold, False otherwise.\n",
    "    \"\"\"\n",
    "    # Initialize a counter for banned words\n",
    "    banned_word_count = 0\n",
    "\n",
    "    #banned words list\n",
    "    #may extend\n",
    "    banned_words = [] \n",
    "    \n",
    "    #threshold\n",
    "\n",
    "    threshold = 10\n",
    "\n",
    "    # Iterate through each word in the transcript\n",
    "    for sentence in transcript:\n",
    "        for word in sentence.split():\n",
    "            # Check if the word is in the list of banned words\n",
    "            if word.lower() in banned_words:\n",
    "                banned_word_count += 1\n",
    "\n",
    "    # Check if the count of banned words exceeds the threshold\n",
    "    if banned_word_count >= threshold:\n",
    "        call.hangup()\n",
    "        return\n",
    "    else:\n",
    "        return\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30ce18f6-c6e4-4fb2-a8f3-54f78914ae24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for creation of white noise in appropriate frame/bytes format\n",
    "#created by our good friend chatgpt, so could need tweaking\n",
    "#consider running prior to create an index of, say, 10 minutes of frames from which we can grab randomly? \n",
    "\n",
    "def white_noise(master_file):\n",
    "    with wave.open(master_file, 'rb') as wf:\n",
    "        sample_width = wf.getsampwidth()  # Get the sample width in bytes\n",
    "        frame_rate = wf.getframerate()  # Get the frame rate (e.g., 8000 Hz)\n",
    "        num_frames = wf.getnframes()  # Get the total number of frames\n",
    "\n",
    "        # Calculate the number of bytes per frame\n",
    "        bytes_per_frame = sample_width\n",
    "\n",
    "        # Set the desired length of the selection (160 frames)\n",
    "        selection_length_frames = 160\n",
    "\n",
    "        # Calculate the maximum frame index to start the selection from\n",
    "        max_start_frame_index = num_frames - selection_length_frames\n",
    "\n",
    "        # Generate a random start frame index within the valid range\n",
    "        start_frame_index = random.randint(0, max_start_frame_index)\n",
    "\n",
    "        # Move to the start frame index\n",
    "        wf.setpos(start_frame_index)\n",
    "\n",
    "        # Read the selected frames\n",
    "        selected_frames = wf.readframes(selection_length_frames)\n",
    "\n",
    "    return selected_frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17666b99-4fcb-472e-8521-3d448c383f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#API interfaces with email and phone numbers\n",
    "\n",
    "def send_text(phone_number):\n",
    "    print(phone_number)\n",
    "\n",
    "def send_email(email):\n",
    "    print(email)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e7c027-1933-4948-b209-f746016c5530",
   "metadata": {},
   "outputs": [],
   "source": [
    "#more chatgpt goodness, this identifies phone numbers using regex\n",
    "\n",
    "import re\n",
    "\n",
    "def spelled_out_to_digit(spelled_out_number):\n",
    "    \"\"\"\n",
    "    Convert spelled out number to digit representation.\n",
    "\n",
    "    Parameters:\n",
    "    - spelled_out_number (str): Spelled out number (e.g., 'four', 'five', 'six').\n",
    "\n",
    "    Returns:\n",
    "    - str: Corresponding digit representation.\n",
    "    \"\"\"\n",
    "    if spelled_out_number == 'zero':\n",
    "        return '0'\n",
    "    elif spelled_out_number == 'one':\n",
    "        return '1'\n",
    "    elif spelled_out_number == 'two':\n",
    "        return '2'\n",
    "    elif spelled_out_number == 'three':\n",
    "        return '3'\n",
    "    elif spelled_out_number == 'four':\n",
    "        return '4'\n",
    "    elif spelled_out_number == 'five':\n",
    "        return '5'\n",
    "    elif spelled_out_number == 'six':\n",
    "        return '6'\n",
    "    elif spelled_out_number == 'seven':\n",
    "        return '7'\n",
    "    elif spelled_out_number == 'eight':\n",
    "        return '8'\n",
    "    elif spelled_out_number == 'nine':\n",
    "        return '9'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def contains_phone_number(sentence):\n",
    "    \"\"\"\n",
    "    Identify if a ten-digit phone number is present in a sentence.\n",
    "\n",
    "    Parameters:\n",
    "    - sentence (str): The input sentence.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: (bool, str) indicating if a ten-digit phone number is found and the phone number itself.\n",
    "    \"\"\"\n",
    "    # Define regex pattern to match ten-digit phone numbers\n",
    "    pattern = r'\\b(?:\\d{10})\\b'\n",
    "\n",
    "    # Find all matches of the pattern in the sentence\n",
    "    matches = re.findall(pattern, sentence)\n",
    "\n",
    "    # Check if any matches are found\n",
    "    if matches:\n",
    "        return True, matches[0]\n",
    "\n",
    "    # Define regex pattern to match spelled out numbers followed by 'digit' or 'digits'\n",
    "    spelled_out_pattern = r'(zero|one|two|three|four|five|six|seven|eight|nine) (?:digit|digits)'\n",
    "    spelled_out_matches = re.findall(spelled_out_pattern, sentence)\n",
    "\n",
    "    # Check if any spelled out matches are found and convert them to digits\n",
    "    for spelled_out_match in spelled_out_matches:\n",
    "        digit = spelled_out_to_digit(spelled_out_match[0])\n",
    "        if digit:\n",
    "            # Create a ten-digit phone number using the converted digit\n",
    "            phone_number = digit * 10\n",
    "            if phone_number in sentence:\n",
    "                return phone_number\n",
    "\n",
    "    return False\n",
    "\n",
    "#even more chatgptness: \n",
    "def contains_email_address(sentence):\n",
    "    \"\"\"\n",
    "    Identify if an email address is present in a sentence.\n",
    "\n",
    "    Parameters:\n",
    "    - sentence (str): The input sentence.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: (bool, str) indicating if an email address is found and the email address itself.\n",
    "    \"\"\"\n",
    "    # Define regex pattern to match email addresses\n",
    "    pattern = r'\\b([A-Za-z0-9._%+-]+)(?: at | @ )([A-Za-z0-9.-]+)\\.[A-Z|a-z]{2,}\\b'\n",
    "\n",
    "    # Find all matches of the pattern in the sentence\n",
    "    matches = re.findall(pattern, sentence)\n",
    "\n",
    "    # Check if any matches are found\n",
    "    if matches:\n",
    "        # Concatenate the username and domain parts to form the email address\n",
    "        email_address = f\"{matches[0][0]}@{matches[0][1]}\"\n",
    "        return email_address\n",
    "\n",
    "    return False\n",
    "\n",
    "#stashes audio in the case that someone reads off an email address or whatever. \n",
    "def stash_audio(filename):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05cab424-70a2-4247-b39d-0ffcee96d091",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines threads of call while VAD is active\n",
    "import threading\n",
    "import time\n",
    "\n",
    "#keeps track of ongoing response\n",
    "my_response = ''\n",
    "#creates empty bytes object\n",
    "tmp_audio_record = b''\n",
    "full_audio_record = b''\n",
    "\n",
    "#keeps track of number of whisper chunks created by silero\n",
    "vadnum = 0\n",
    "\n",
    "#keeps track of which whisper chunks have been processed\n",
    "whisper_increment = 0\n",
    "\n",
    "def thread_1():\n",
    "    while True:\n",
    "        if vad('full_audio_record.wav',current_transcript) == True:\n",
    "            return True\n",
    "def thread_2():\n",
    "    while True:\n",
    "        full_audio_record += call.read_audio()\n",
    "        tmp_audio_record += call.read_audio()\n",
    "        with wave.open(str(vadnum)+'audio_record.wav', 'wb') as wf:\n",
    "            wf.setnchannels(1)  # Set the number of channels (1 for mono, 2 for stereo)\n",
    "            wf.setsampwidth(1)  # Set the sample width in bytes (2 bytes for 16-bit audio)\n",
    "            wf.setframerate(8000)  # Set the frame rate (e.g., 44100 Hz)\n",
    "            wf.writeframes(tmp_audio_record)  # Write the audio data to the file\n",
    "        with wave.open('full_audio_record.wav', 'wb') as wf:\n",
    "            wf.setnchannels(1)  # Set the number of channels (1 for mono, 2 for stereo)\n",
    "            wf.setsampwidth(1)  # Set the sample width in bytes (2 bytes for 16-bit audio)\n",
    "            wf.setframerate(8000)  # Set the frame rate (e.g., 44100 Hz)\n",
    "            wf.writeframes(full_audio_record)  # Write the audio data to the file\n",
    "def thread_3():\n",
    "    while True:\n",
    "        if vadnum <= whisper_increment:\n",
    "            if tmp_current_transcript in current_transcript:\n",
    "                current_transcript.replace(tmp_current_transcript,'')\n",
    "            tmp_current_transcript = whisper_audio_transcript(str(vadnum)+'audio_record.wav')\n",
    "            current_transcript += tmp_current_transcript\n",
    "        elif vadnum > whisper_increment:\n",
    "            tmp_current_transcript = whisper_audio_transcript(str(vadnum)+'audio_record.wav')\n",
    "            current_transcript += tmp_current_transcript\n",
    "            whisper_increment += 1\n",
    "            \n",
    "\n",
    "def thread_4():\n",
    "    while True:\n",
    "        my_response = response(current_transcript)\n",
    "        my_ssml_response = \"\"\"<speak> <prosody rate=\"slow\">\"\"\" + my_response + \"\"\"</prosody> </speak>\"\"\"\n",
    "        my_tts(my_ssml_response,\"response.wav\")\n",
    "\n",
    "def thread_5():\n",
    "    while True:\n",
    "        #uses the whitenoise.wav file as placeholder \n",
    "        call.write_audio(white_noise(master_file.wav))\n",
    "        time.sleep(0.02)\n",
    "\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6168512d-b6ad-42ab-8954-ba3d82d960b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines threads of call while VAD is inactive\n",
    "\n",
    "#note other functions will take place before activation, inlcuding clearing local transcript and audiofile, along with summarization\n",
    "\n",
    "#global variable to indicate llm_response completion\n",
    "llm_response_finished = False\n",
    "full_response = ''\n",
    "\n",
    "#global variable indicating number of chunks full LLM response is in\n",
    "index_count = 0\n",
    "llm_responses_completed = 0 \n",
    "\n",
    "def thread_a():\n",
    "    while True:\n",
    "        #adding 'a' so that continued audiofile compilation won't make sub-200ms judgements\n",
    "        if vad('audio_record.wav',\"a\") == False:\n",
    "            #set talked-over variable\n",
    "            talk_over_gap += 0.3\n",
    "            audio_record = ''\n",
    "            return True\n",
    "def thread_b():\n",
    "    while llm_response_finished == False and llm_responses_completed < index_count:\n",
    "        call_writer('response.wav')\n",
    "        #setting global variable to indicate whether LLM has finished talking\n",
    "        if llm_responses_completed < index_count:\n",
    "            call_writer(str(llm_responses_completed)+'llmresponse.wav')\n",
    "            llm_responses_completed += 1\n",
    "        else:\n",
    "            #uses the whitenoise.wav file as placeholder\n",
    "            call.read_audio(white_noise('whitenoise.wav'))\n",
    "            time.sleep(0.02)\n",
    "    return\n",
    "#reuse thread_2, needed for VAD\n",
    "#edited to enable chunking, adding tmp file\n",
    "def thread_d():\n",
    "    while True:\n",
    "        if vad('tmp_audio_record.wav',current_transcript) == True:\n",
    "            return True\n",
    "\n",
    "#runs full_whisper. transcript_update_success ensures in case of termination that partial transcript is still grabbed.\n",
    "transcript_update_success = False\n",
    "def thread_e():\n",
    "        transcript = full_whisper(\"full_audio_record.wav\")\n",
    "        update_transcript(transcript,\"user\",current_transcript)\n",
    "        transcript_update_success = True\n",
    "        \n",
    "\n",
    "def thread_c():\n",
    "    #removing re-sts of thread due to latency issues\n",
    "    #current_transcript = whisper_audio_transcript('audio_record.wav')\n",
    "    full_response = script(current_transcript,my_response)\n",
    "    response_chunks = separate_into_sentences_with_ssml(full_response)\n",
    "    index_count = len(response_chunks)\n",
    "    for i in response_chunks:\n",
    "        my_tts(response_chunks,str(index(i))+'llmresponse.wav')\n",
    "    llm_response_finished = True\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "262eb6aa-3bb2-45c6-8b19-0993cfc520d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Maybe you meant '==' or ':=' instead of '='? (1449828404.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[14], line 6\u001b[1;36m\u001b[0m\n\u001b[1;33m    if answering_machine = 1:\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax. Maybe you meant '==' or ':=' instead of '='?\n"
     ]
    }
   ],
   "source": [
    "#checks to ensure call is still active\n",
    "def thread_z():\n",
    "    #local timecount variable\n",
    "    current_time = 0\n",
    "    #whether we've attempted to raise the other end of the call\n",
    "    if answering_machine == 1:\n",
    "        call_raise = True\n",
    "    else: \n",
    "        call_raise = False\n",
    "    while True:\n",
    "        if call.state != CallState.ANSWERED:\n",
    "            return\n",
    "        elif call_raise = False and current_time > 10:\n",
    "            #if it's been longer than X length of time, we play inquiry\n",
    "            my_response = response(\"Are you still there?\")\n",
    "            my_tts(my_response,'stillthere.wav')\n",
    "            call_writer('stillthere.wav')\n",
    "            current_time = 0\n",
    "            call_raise = True\n",
    "        elif call_raise = True and current_time > 10:\n",
    "            #if have already tried to raise other end of call once, hang up\n",
    "            call.hangup()\n",
    "        else: \n",
    "            time.sleep(0.02)\n",
    "            current_time += 0.02\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07371a9e-e442-4e7d-a945-ed8aa711538f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 15) (1630852504.py, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[16], line 15\u001b[1;36m\u001b[0m\n\u001b[1;33m    if dtmf == \"9:\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 15)\n"
     ]
    }
   ],
   "source": [
    "#heart of the function\n",
    "\n",
    "#note that thread_1 and thread_a may not be needed based on functionality of while loop, and are possibly redundant as a result\n",
    "\n",
    "#note global variable answering_machine, which is set to 0, then to 1 after first circuit is complete. If it is an answering machine it will\n",
    "#in all likelihood not complete a second circuit. Thus we deactivate raise_call during 1. \n",
    "\n",
    "answering_machine = 0\n",
    "\n",
    "\n",
    "def answer(call):\n",
    "    phone_number = current_phone\n",
    "    #add function that records datetime.now() when callstate changes to ANSWERED at datetime_start\n",
    "    datetime_start = datetime.now()\n",
    "    while call.state == CallState.ANSWERED:\n",
    "        #do not call function\n",
    "        dtmf = call.get_dtmf()\n",
    "        if dtmf == \"8\":\n",
    "            do_not_call(phone_number)\n",
    "            call.hangup()\n",
    "            \n",
    "        #waiting for other person to begin talking\n",
    "        while vad(audiofile,transcript) == True:\n",
    "            threading.Thread(target=thread_1).start()\n",
    "            threading.Thread(target=thread_2).start()\n",
    "            threading.Thread(target=thread_3).start()\n",
    "            threading.Thread(target=thread_z).start()\n",
    "        threading.Thread(target=thread_1).stop()\n",
    "        threading.Thread(target=thread_2).stop()\n",
    "        threading.Thread(target=thread_3).stop()\n",
    "        threading.Thread(target=thread_z).stop()\n",
    "    \n",
    "        \n",
    "        #while the other person is talking\n",
    "        while vad(audiofile,transcript) == False:\n",
    "            threading.Thread(target=thread_1).start()\n",
    "            threading.Thread(target=thread_2).start()\n",
    "            threading.Thread(target=thread_3).start()\n",
    "            threading.Thread(target=thread_4).start()\n",
    "            threading.Thread(target=thread_5).start()\n",
    "        threading.Thread(target=thread_1).stop()\n",
    "        threading.Thread(target=thread_2).stop()\n",
    "        threading.Thread(target=thread_3).stop()\n",
    "        threading.Thread(target=thread_4).stop()\n",
    "        threading.Thread(target=thread_5).stop()\n",
    "    \n",
    "        #clears out variables\n",
    "        full_audio_record = b''\n",
    "        tmp_audio_record = b''\n",
    "        \n",
    "        #initiates new call before thank-you message\n",
    "        if call_stage == 3:\n",
    "            call_maker(False,False)\n",
    "        \n",
    "        #while our AI is talking\n",
    "        while vad(audiofile,\"a\") == True and :\n",
    "            threading.Thread(target=thread_d).start()\n",
    "            threading.Thread(target=thread_a).start()\n",
    "            threading.Thread(target=thread_b).start()\n",
    "            threading.Thread(target=thread_c).start()\n",
    "            threading.Thread(target=thread_e).start()\n",
    "        threading.Thread(target=thread_e).stop()\n",
    "        threading.Thread(target=thread_d).stop()\n",
    "        threading.Thread(target=thread_a).stop()\n",
    "        threading.Thread(target=thread_b).stop()\n",
    "        threading.Thread(target=thread_c).stop()\n",
    "        \n",
    "        if transcript_update_success == False:\n",
    "                update_transcript(transcript,\"user\",current_transcript)\n",
    "        phonenum = contains_phone_number(current_transcript)\n",
    "        if phonenum != False:\n",
    "            send_text(phonenum)\n",
    "        email = contains_email_address(current_transcript)\n",
    "        if email != False:\n",
    "            send_email(email)\n",
    "        if phonenum or email != False:\n",
    "            stash_audio(\"full_audio_record.wav\")\n",
    "        current_transcript = ''\n",
    "        update_transcript(transcript,\"assistant\",(my_response + full_response))\n",
    "        my_response = ''\n",
    "        full_response = ''\n",
    "        answering_machine += 1\n",
    "        if answering_machine > 1:\n",
    "            call_stage = 1\n",
    "        if answering_machine > 3:\n",
    "            call_stage = 2\n",
    "        if call_stage == 3:\n",
    "            call_maker(False,False)\n",
    "        #reduces the gap by half its deviation from 200ms if a gap has been created\n",
    "        if talk_over_gap > 0.2:\n",
    "            talk_over_gap = talk_over_gap - (talk_over_gap-0.2)/2\n",
    "    #checks to make sure wasn't hung up on do not call\n",
    "    dtmf = call.get_dtmf()\n",
    "    if dtmf == \"8\":\n",
    "        do_not_call(current_phone)\n",
    "    #pushes transcript to file\n",
    "    push_transcript(transcript)\n",
    "    call_maker(True,True)\n",
    "    #resets global variables\n",
    "    llm_response_finished = False\n",
    "    full_response = ''\n",
    "    #keeps track of ongoing response\n",
    "    my_response = ''\n",
    "    #creates empty bytes object\n",
    "    tmp_audio_record = b''\n",
    "    #global variable for each call transcript\n",
    "    transcript = []\n",
    "    #global variable for call stage\n",
    "    call_stage = 0\n",
    "    #global variable for current transcript\n",
    "    current_transcript = ''\n",
    "    full_transcript = ''\n",
    "    answering_machine = 0\n",
    "    datetime_start = ''\n",
    "    index_count = 0\n",
    "    llm_responses_completed = 0 \n",
    "    tmp_audio_record = b''\n",
    "    full_audio_record = b''\n",
    "    transcript_update_success = False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832a4693-ca7b-457b-ad89-1408ad892b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the actual pyvoip call\n",
    "phone = VoIPPhone(asteriskip, 5060, extension, extension_passowrd,myIP=IP, callCallback=answer)\n",
    "phone.start()\n",
    "call_maker(False,False)\n",
    "input('Press enter to disable the phone')\n",
    "phone.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
